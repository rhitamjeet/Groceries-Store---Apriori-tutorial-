---
title: "Groceries Store - Apriori Association Rule Mining"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = F, message = F)
```

#Project Brief 
- We have data of transactions from a grocery store. Each transactions contains one or more items purchased by various customers.We will try to find out buying patterns in the transactions and use the insights to build a better business model for the store. Based on user behaviour we will try to model the algorithm so that we can drive higher sales. - We will be using the apriori algoritm to find association rules, also called Association Rules Mining.

#Apriori Algorithm 
- Apriori algorithm is based on conditional probabilities and helps us determine the likelihood of items being bought together based on a - priori data. There are three important parameters - support, confidence and lift. Suppose there a set of transactions with item1 --> item 2. So support for item 1 will be defined by n(item1) / n(total transactions). Confidence on the other hand is defined as, n(item1 & item2) / n(item1). So, confidence tells us the strength of the association and support tells us the relevance of the rule. Because we dont want to include rules about items that are seldom bought, or in other words, have low support. Lift is Confidence/Support. Higher the lift, more the significance of applying the apriori algorithm to determine the rule.

#Importing the Data
```{r}

library(arules)
# Importing the raw data in the form of transcations(using arules package)
groceries = read.transactions("D:/Machine Learning/groceries.csv",sep = ',',rm.duplicates = T)

summary(groceries)
# So we have a set of 9835 transactions with 169 unique items.
# We also see that on average a customer buys 4.4 products and median is 3.0 products.  
```

# We see the most frequently occuring items first
```{r}

itemFrequencyPlot(groceries,topN = 20)

```

- The most commonly bought items are Whole milk, vegetables, rolls/buns, soda etc.

- Now for applying the apriori algorithm, we need to set a minimum support and confidence. We are interested first in finding a larger set of rules. so we set support and confidence low. 

#Model fitting - Apriori 
```{r}
a1 = apriori(groceries,control = list(verbose = F),
             parameter = list(minlen = 2,supp = 0.01,conf = 0.3))

library(arulesViz)
head(inspect(sort(a1,by = 'confidence')),20) # to have a look at the rules 

# We get a set of 125 rules.

summary(a1) # we get a summary of the rules

plot(sort(a1,by = 'confidence'), method = "grouped")


```

- We see that the inter quartile range for support lies between 0.011 & 0.022. So, we will choose 0.22 as the minimum support.


#Iteration 2 - for optimization

```{r}
a2 = apriori(groceries,control = list(verbose = F),
             parameter = list(minlen = 2,supp = 0.022,conf = 0.3))

quality(a2) = round(quality(a2),digits = 3)

#We also remove redundant rules

subset.matrix = is.subset(a2, a2, sparse = F)
subset.matrix[lower.tri(subset.matrix, diag= T)] = NA

redundant = colSums(subset.matrix,na.rm = T) >=1

which(redundant)

rules.pruned = a2[!redundant]

plot(rules.pruned, method = "grouped")

a_sorted = inspect(sort(rules.pruned,by = 'confidence')) 
a_sorted

```

- Now having looked at the rules , we trim them further by putting the lift > 1.5

```{r}

a_sorted = a_sorted[a_sorted$lift>1.5,]

summary(a_sorted)

dim(a_sorted)

a_sorted

# Finally,we get a set of 20 rules with a minimum confidence of 0.3 , min lift of 1.5 and min support of  0.22

```

